# Gudu SQLFlow Lite version for docker

### サンプルコマンドの想定ディレクトリ構成

```txt
data/
  input/      - 分析対象のSQLファイル
  output/     - 出力ディレクトリ
    dlineage/ - 分析結果、webサーバーの可視化対象
```

### 最新バージョン取得

```bash
docker image pull \
  ghcr.io/suwa-sh/python_data_lineage_docker:latest
```

### webサーバー起動

```bash
docker run --rm -d \
  --name sqlflow \
  -p 8000:8000 \
  -v ./data:/app/widget/data \
  ghcr.io/suwa-sh/python_data_lineage_docker:latest

# データリネージ
open http://localhost:8000
# ER図
open http://localhost:8000/er.html


# 停止する場合
docker container stop sqlflow
```

### データリネージ分析

```bash
docker run -it --rm \
  -v ./data:/app/data \
  ghcr.io/suwa-sh/python_data_lineage_docker:latest \
  [options]

# sample
docker run -it --rm \
  -v ./data:/app/data \
  ghcr.io/suwa-sh/python_data_lineage_docker:latest \
  /t oracle /f data/input/samples/oracle_plsql.sql /graph

docker run -it --rm \
  -v ./data:/app/data \
  ghcr.io/suwa-sh/python_data_lineage_docker:latest \
  /t mssql /f data/input/samples/sqlserver_er.sql /er /graph
```

- options

  ```sh
    /t: Required, specify the database type
      
      The valid value: access,bigquery,couchbase,dax,db2,greenplum, gaussdb, hana,hive,impala,informix,mdx,mssql,
          sqlserver,mysql,netezza,odbc,openedge,oracle,postgresql,postgres,redshift,snowflake,
          sybase,teradata,soql,vertica 

      the default value is oracle

    /f: optional, The SQL file that needs to be processed, if this option is not specified, /d must be speicified.

    /d: optional, All SQL files under this directory will be processed.

    /j: optional, The analyzed result will include the join relationship.

    /s: optional, Ignore the intermediate results of the output data lineage.

    /topselectlist: optional, output the column in select list. this option valid only /s is specified.

    /withTemporaryTable: optional, only valid use with /s option, including the data lineage of temporary table used in the SQL.

    /i: optional, this option work almost the same as /s option, but will keep the data lineage generated by function call.

    /if: optional, keep all the intermediate result in the output data lineage, but remove the result derived from function call.

    /ic: optional, ignore the coordinate in the output.

    /lof: optional, if a column in the SQL is not qualifiey with a table name, and multiple tables are used in the from clause, then, the column will be linked to the first table in from clause.

    /traceView: optional, only list source table and view, ignore all intermediate result.

    /json: optional, ouput in json format.

    /tableLineage [/csv /delimiter]: optional, only output data lineage at table level.

    /csv: optional, output the data lineage in CSV format.

    /delimiter: optional, specify the separate character used in CSV output.

    /env: optional, specify a metadata.json to provide the metadata that can be used during SQL analysis.

    /transform: optional, includind the code that do the transform.

    /coor: optional, whether including the coordinate in the output.

    /defaultDatabase: optional, specify a default database.

    /defaultSchema: optional, specify a default schema.

    /showImplicitSchema: optional, Display the schema information inferred from the SQL statement.

    /showConstant: optional, whether show constant.

    /treatArgumentsInCountFunctionAsDirectDataflow: optional,treate column used in count function as a direct dataflow.

    /filterRelationTypes: optional, supported types: fdd，fdr，join，call，er，seperated by comma if multiple values are specified.

    /graph: optional, automatically open web browser to show the data lineage diagram.
    /er: optional, automatically open web browser to show the ER diagram.
  ```

### DELETE/TRUNCATE文抽出

SQLファイルからDELETE文とTRUNCATE文を抽出してCSV形式で出力します。

```bash
docker run -it --rm \
  -v ./data:/app/data \
  ghcr.io/suwa-sh/python_data_lineage_docker:latest \
  analyze_delete INPUT_FILE [OUTPUT_DIR]

# sample
docker run -it --rm \
  -v ./data:/app/data \
  ghcr.io/suwa-sh/python_data_lineage_docker:latest \
  analyze_delete data/input/test_delete_truncate.sql data/output/
```

- 出力例：`{OUTPUT_DIR}/{INPUT_FILE_NAME}_delete.csv`
  ```csv
  ファイル,delete/truncate,テーブル,条件
  test.sql,delete,emp,empno = 7369
  test.sql,truncate,temp_table,-
  ```

### SQL分割

複雑なSQLファイルをDDL、CTE、サブクエリ、メインクエリに分割します。  
ファイル名の昇順にソートして連結すると、元ファイルと同じ定義内容になります。

```bash
docker run -it --rm \
  -v ./data:/app/data \
  ghcr.io/suwa-sh/python_data_lineage_docker:latest \
  split INPUT_FILE [OUTPUT_DIR]

# 実行中のコンテナで起動する場合
docker run -it --rm \
  -v ./data:/app/data \
  ghcr.io/suwa-sh/python_data_lineage_docker:latest \
  split data/input/test_split.sql data/output/split
```

- 出力ファイル例：
  - `元ファイル名_01.sql` - DDL文
  - `元ファイル名_02.sql` - CTE（WITH句）
  - `元ファイル名_03.sql` - 抽出されたサブクエリ(WITH句として抽出)
  - `元ファイル名_main.sql` - メインクエリ

### 一括データリネージ分析

指定ディレクトリ直下の全サブディレクトリに対して、データリネージ分析をディレクトリモード（/d）で実行します。  
SQL分割機能の結果を一括で分析できます。  
`/graph`オプションをつけておけば、起動中のwebサーバーで結果を選んで可視化できます。

```bash
docker run -it --rm \
  -v ./data:/app/data \
  ghcr.io/suwa-sh/python_data_lineage_docker:latest \
  bulk_dlineage data/output/split [dlineage-options]

# sample
docker run -it --rm \
  -v ./data:/app/data \
  ghcr.io/suwa-sh/python_data_lineage_docker:latest \
  bulk_dlineage data/output/split /t oracle /graph
```
